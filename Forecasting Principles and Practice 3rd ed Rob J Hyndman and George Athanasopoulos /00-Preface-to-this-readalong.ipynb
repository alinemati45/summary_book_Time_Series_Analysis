{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contents](Contents.ipynb)\n",
    "• [Next: Time series graphics](02-Time-series-graphics.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface to this read-along\n",
    "\n",
    "* [What this is and isn't](#What-this-is-and-isn't)\n",
    "* [Software environment](#Software-environment)\n",
    "* [Datasets](#Datasets)\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can be forecast?\n",
    "\n",
    "The predictability of an event or a quantity depends on several factors including:\n",
    "\n",
    "- how well we understand the factors that contribute to it;\n",
    "- how much data is available;\n",
    "- how similar the future is to the past;\n",
    "- whether the forecasts can affect the thing we are trying to forecast.\n",
    "\n",
    "Forecasting should be an integral part of the decision-making activities of management, as it can play an important role in many areas of a company. Modern organisations require short-term, medium-term and long-term forecasts, depending on the specific application.\n",
    "\n",
    "- Short-term forecasts\n",
    "are needed for the scheduling of personnel, production and transportation. As part of the scheduling process, forecasts of demand are often also required.\n",
    "- Medium-term forecasts\n",
    "are needed to determine future resource requirements, in order to purchase raw materials, hire personnel, or buy machinery and equipment.\n",
    "- Long-term forecasts\n",
    "are used in strategic planning. Such decisions must take account of market opportunities, environmental factors and internal resources.\n",
    "\n",
    "## Time series forecasting\n",
    "Examples of time series data include:\n",
    "\n",
    "- Annual Google profits\n",
    "- Quarterly sales results for Amazon\n",
    "- Monthly rainfall\n",
    "- Weekly retail sales\n",
    "- Daily IBM stock prices\n",
    "- Hourly electricity demand\n",
    "- 5-minute freeway traffic counts\n",
    "- Time-stamped stock transaction data\n",
    "\n",
    "\n",
    "If there are no data available, or if the data available are not relevant to the forecasts, \n",
    "then **qualitative forecasting** methods must be used.\n",
    "\n",
    "**Quantitative forecasting** can be applied when two conditions are satisfied:\n",
    "\n",
    "- Numerical information about the past is available;\n",
    "- it is reasonable to assume that some aspects of the past patterns will continue into the future.\n",
    "\n",
    "Most quantitative prediction problems use either time series data (collected at regular intervals over time) or cross-sectional data (collected at a single point in time). Most quantitative prediction problems use either time series data (collected at regular intervals over time) or cross-sectional data (collected at a single point in time). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor variables and time series forecasting\n",
    "\n",
    "An explanatory model is useful because it incorporates information about other variables, rather than only historical values of the variable to be forecast. However, there are several reasons a forecaster might select a time series model rather than an explanatory or mixed model. \n",
    "- First, the system may not be understood, and even if it was understood it may be extremely difficult to measure the relationships that are assumed to govern its behaviour. \n",
    "- Second, it is necessary to know or forecast the future values of the various predictors in order to be able to forecast the variable of interest, and this may be too difficult. \n",
    "- Third, the main concern may be only to predict what will happen, not to know why it happens. \n",
    "- Finally, the time series model may give more accurate forecasts than an explanatory or mixed model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basic steps in a forecasting task\n",
    "\n",
    "### Step 1: Problem definition.\n",
    "Defining the problem carefully requires an understanding of the way the forecasts will be used, who requires the forecasts, and how the forecasting function fits within the organisation requiring the forecasts. A forecaster needs to spend time talking to everyone who will be involved in collecting data, maintaining databases, and using the forecasts for future planning.\n",
    "\n",
    "### Step 2: Gathering information.\n",
    "There are always at least two kinds of information required: (a) statistical data, and (b) the accumulated expertise of the people who collect the data and use the forecasts. However, remember that good statistical models will handle evolutionary changes in the system; don’t throw away good data unnecessarily.\n",
    "\n",
    "### Step 3: Preliminary (exploratory) analysis.\n",
    "Always start by graphing the data. Are there consistent patterns? Is there a significant trend? Is seasonality important? Is there evidence of the presence of business cycles? Are there any outliers in the data that need to be explained by those with expert knowledge? How strong are the relationships among the variables available for analysis? \n",
    "\n",
    "### Step 4: Choosing and fitting models.\n",
    "The best model to use depends on the availability of historical data, the strength of relationships between the forecast variable and any explanatory variables, and the way in which the forecasts are to be used. It is common to compare two or three potential models. Each model is itself an artificial construct that is based on a set of assumptions (explicit and implicit) and usually involves one or more parameters which must be estimated using the known historical data. We will discuss regression models , exponential smoothing methods , Box-Jenkins ARIMA models (Chapter 9), Dynamic regression models , Hierarchical forecasting , and several advanced methods including neural networks and vector autoregression.\n",
    "\n",
    "### Step 5: Using and evaluating a forecasting model.\n",
    "Once a model has been selected and its parameters estimated, the model is used to make forecasts. The performance of the model can only be properly evaluated after the data for the forecast period have become available. A number of methods have been developed to help in assessing the accuracy of forecasts. There are also organisational issues in using and acting on the forecasts. A brief discussion of some of these issues is given in Chapter 5. When using a forecasting model in practice, numerous practical issues arise such as how to handle missing values and outliers, or how to deal with short time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notes are a Python-centered read-along of the excellent [Forecasting: Principles and Practice](https://otexts.com/fpp3/index.html) by Rob J Hyndman and George Athanasopoulos [$^1$](#cite1).  The author of these notes is [Mike Richman](zgana.github.io).  I am about six months into my first data science job, which comes on the heels of about a decade as a Ph.D. and postdoc in neutrino astrophysics.\n",
    "\n",
    "In industry, we have to deal with timeseries data in a way that shares little in common with my past work as an academic.  Prior to this exercise, my only experience with forecasting consists of an interview take-home for a trading-related job I did not ultimately take.\n",
    "\n",
    "Deep learning methods are all the rage right now, and rightly so.  See [here](https://arxiv.org/abs/2004.13408) for a recent overview.  However, until relatively recently, it was less clear that deep learning could significantly improve on mathematically straightforward models implemented by experienced forecasters.\n",
    "\n",
    "Given an opportunity for some personal research, I decided to take the time to go through *Forecasting: Principles and Practice* in detail.  This serves two purposes.  First, as they say, you must walk before you can run; I should make sure I have the basics down before I get too deep into the latest research architectures.  Second, I did not easily come across a comparable resource based on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What this is and isn't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in no way a substitute for the original source material.  It could be a companion for the original.  As noted above, I am new to this stuff.  That may result in doing some things in silly ways.  But if you follow the original text with these notes, you should rarely if ever feel like you've reached a dead end.\n",
    "\n",
    "Similarly, the tools available in Python are not (or do not currently appear to be) a complete substitute for those available in R.  There are cells in these notebooks that look ridiculous compared to the R code they mimic, and I think only some of this is my fault.  Timeseries analysis is a core strength of R.  Python has different strengths.  If you love Python, or you have no choice but to use it in your work, then tolerating apparent shortcomings in its ecosystem is worth it.\n",
    "\n",
    "I will include some comments on the code, but only links to the source text for deeper exposition.\n",
    "\n",
    "The notes start with Chapter 2, as there's essentially no code in Chapter 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notes make use of the following libraries:\n",
    "\n",
    "* matplotlib                    3.2.0\n",
    "* numpy                         1.19.0\n",
    "* pandas                        1.0.3\n",
    "* pandas-datareader             0.8.1\n",
    "* pmdarima                      1.6.1\n",
    "* rdatasets                     0.1.0\n",
    "* seaborn                       0.10.0\n",
    "* statsmodels                   0.11.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things streamlined, we standardize the working environment in [utils.py](utils.py), from which I will `import *` in the per-chapter notebooks.  ~Because I love manually syncing files~ for convience, the contents of that file are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pmdarima as pmd\n",
    "\n",
    "import rdatasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "plt.rc('axes', titlesize='medium')\n",
    "plt.rc('axes', titlelocation='left')\n",
    "plt.rc('axes.spines', right=False)\n",
    "plt.rc('axes.spines', top=False)\n",
    "sizets = (8,4.5)\n",
    "plt.rc('figure', figsize=sizets)\n",
    "\n",
    "\n",
    "def summarize(gb, f):\n",
    "    \"\"\"Summarize grouped things.\"\"\"\n",
    "    return gb.apply(lambda x: pd.Series(f(x)))\n",
    "\n",
    "\n",
    "def compute(df, f):\n",
    "    \"\"\"Compute new (or replacement) columns.\"\"\"\n",
    "    newdf = pd.DataFrame(f(df), index=df.index)\n",
    "    dropcols = [col for col in newdf.columns if col in df.columns]\n",
    "    if dropcols:\n",
    "        df = df.drop(columns=dropcols)\n",
    "    return df.join(newdf)\n",
    "\n",
    "\n",
    "def set_freq(df, freq=None):\n",
    "    \"\"\"Set frequency of DateTimeIndex.\"\"\"\n",
    "    if freq is None:\n",
    "        freq = pd.infer_freq(df.index)\n",
    "    return df.asfreq(freq)\n",
    "\n",
    "\n",
    "def extend_timeseries(df, tmax=None, tmin=None, dt=None):\n",
    "    \"\"\"Extend timeseries data to later or earlier times.\"\"\"\n",
    "    freq = df.index.freq\n",
    "    if tmax is tmin is dt is None:\n",
    "        dt = 1\n",
    "    if tmin is None:\n",
    "        tmin = df.index.min()\n",
    "    if tmax is None:\n",
    "        tmax = df.index.max()\n",
    "    if dt is not None:\n",
    "        if isinstance(dt, int):\n",
    "            if dt > 0:\n",
    "                tmax += dt * freq\n",
    "            elif dt < 0:\n",
    "                tmin += dt * freq\n",
    "        else:\n",
    "            dt = pd.to_timedelta(dt)\n",
    "            if dt > pd.to_timedelta('0d'):\n",
    "                tmax += dt\n",
    "            else:\n",
    "                tmin -= dt\n",
    "    index = pd.date_range(tmin, tmax, freq=freq)\n",
    "    return df.reindex(index)\n",
    "\n",
    "\n",
    "def suptitle(fig, text=None, **kw):\n",
    "    \"\"\"Add a nice left-aligned suptitle.\"\"\"\n",
    "    if text is None:\n",
    "        fig, text = plt.gcf(), fig\n",
    "    fig = fig.figure or fig\n",
    "    fig.text(fig.subplotpars.left, .99, text, ha='left', va='top', size='large', **kw)\n",
    "    \n",
    "    \n",
    "def rlabel(ax, label=None, **kw):\n",
    "    \"\"\"Add a right-side axis title.\"\"\"\n",
    "    if label is None:\n",
    "        ax, label = plt.gca(), ax\n",
    "    bbox = kw.pop('bbox', dict(facecolor='.9', alpha=0.2))\n",
    "    ax.text(1, .5, label,\n",
    "            rotation=-90, ha='left', va='center', transform=ax.transAxes,\n",
    "            bbox=bbox, **kw)\n",
    "    \n",
    "\n",
    "def xdate(ax, fmt=None, freq=None):\n",
    "    \"\"\"Tweak x-axis date formatting.\"\"\"\n",
    "    dates = plt.matplotlib.dates\n",
    "    if fmt is None:\n",
    "        ax, fmt = plt.gca(), ax\n",
    "    if freq:\n",
    "        t1, t2 = dates.num2date(ax.get_xticks()[[0,-1]])\n",
    "        ticks = pd.date_range(t1, t2, freq=freq)\n",
    "        ax.set_xticks(ticks)\n",
    "    ax.xaxis.set_major_formatter(dates.DateFormatter(fmt))\n",
    "    \n",
    "    \n",
    "def plot_tsresiduals(Y, y, acf_lags=np.r_[1:26]):\n",
    "    \"\"\"Plot timeseries residuals for ground truth Y and estimate y.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    gs = plt.GridSpec(3, 2, figure=fig)\n",
    "    ts_ax = fig.add_subplot(gs[0,:])\n",
    "    axs = np.array([ts_ax] + [fig.add_subplot(gs[i,j]) for j in (0,1) for i in (1,2)])\n",
    "    ax, rax, hax, acfax, pacfax = axs\n",
    "    #((ax, hax), (rax, acfax)) = axs\n",
    "    mask = ~(np.isnan(Y) | np.isnan(y))\n",
    "    Y, y = Y[mask], y[mask]\n",
    "    #dy = y - Y\n",
    "    # I was surprised by this convention but ok\n",
    "    dy = Y - y\n",
    "    ax.plot(Y, color='k')\n",
    "    ax.plot(y)\n",
    "    ax.set(title='Time Series')\n",
    "    lim = 1.1 * max(-dy.min(), dy.max())\n",
    "    lim = -lim, lim\n",
    "    rax.plot(dy)\n",
    "    rax.set(ylim=lim, title='Residuals')\n",
    "    sns.distplot(dy, bins=np.linspace(lim[0], lim[1], 22),\n",
    "                 hist=True, kde=True, rug=True, ax=hax)\n",
    "    hax.set(title='Residual Distribution')\n",
    "    sm.graphics.tsa.plot_acf(dy, lags=acf_lags, ax=acfax)\n",
    "    sm.graphics.tsa.plot_pacf(dy, lags=acf_lags, ax=pacfax)\n",
    "    for a in axs.ravel():\n",
    "        a.grid()\n",
    "    plt.tight_layout()\n",
    "    return fig, axs\n",
    "\n",
    "\n",
    "def RMSE(Y, y):\n",
    "    \"\"\"Root-mean-square error.\"\"\"\n",
    "    return np.sqrt(np.mean((Y-y)**2))\n",
    "def MAE(Y, y):\n",
    "    \"\"\"Mean absolute error.\"\"\"\n",
    "    return np.mean(np.abs(Y-y))\n",
    "def MAPE(Y, y):\n",
    "    \"\"\"Mean absolute percent error.\"\"\"\n",
    "    return 100 * np.mean(np.abs((Y-y)/Y))\n",
    "def MASE(Y, y):\n",
    "    \"\"\"TODO\"\"\"\n",
    "    return np.nan # TODO\n",
    "\n",
    "\n",
    "def tsaccuracy(Ytest, models):\n",
    "    \"\"\"Gather some metrics for a few models.\"\"\"\n",
    "    fs = RMSE, MAE, MAPE, MASE\n",
    "    return pd.DataFrame({\n",
    "        label: [ f(Ytest, model.predict(Ytest.index.min(), Ytest.index.max()))\n",
    "                for f in (RMSE, MAE, MAPE, MASE) ]\n",
    "        for (label, model) in models.items()\n",
    "    }, index=[f.__name__ for f in fs]).T\n",
    "\n",
    "def ciclean(ci_df):\n",
    "    \"\"\"Clean up conf_int() result column names.\"\"\"\n",
    "    ci_df = ci_df.copy()\n",
    "    ci_df.columns = 'lower', 'upper'\n",
    "    return ci_df\n",
    "\n",
    "\n",
    "legend_right = dict(loc='center left', bbox_to_anchor=[1, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdatasets\n",
      "  Downloading rdatasets-0.1.0.tar.gz (18.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/parsanemati/Library/r-miniconda-arm64/envs/tensorflow/lib/python3.8/site-packages (from rdatasets) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/parsanemati/.local/lib/python3.8/site-packages (from pandas->rdatasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/parsanemati/Library/r-miniconda-arm64/envs/tensorflow/lib/python3.8/site-packages (from pandas->rdatasets) (2022.4)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/parsanemati/Library/r-miniconda-arm64/envs/tensorflow/lib/python3.8/site-packages (from pandas->rdatasets) (1.23.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/parsanemati/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->rdatasets) (1.16.0)\n",
      "Building wheels for collected packages: rdatasets\n",
      "  Building wheel for rdatasets (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rdatasets: filename=rdatasets-0.1.0-py3-none-any.whl size=19168565 sha256=52d1df7e1105e2366bfa89433b0e56cc7cf70810645a9912b8a4d313eb43c2f3\n",
      "  Stored in directory: /Users/parsanemati/Library/Caches/pip/wheels/75/b9/ac/e89acbcd5ad7824af24ed4458d5b913c5cb41753527dc513ca\n",
      "Successfully built rdatasets\n",
      "Installing collected packages: rdatasets\n",
      "Successfully installed rdatasets-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rdatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure I could easily access the example data used in the book, I exported the datasets using [this R notebook](R-export-datasets.ipynb).  In hindsight (not to be confused with [Hyndsight](https://robjhyndman.com/hyndsight/)!) I probably could have made more use of [rdatasets](https://pypi.org/project/rdatasets/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"cite1\"></div>\n",
    "$^1$ Hyndman, R.J., & Athanasopoulos, G. (2019) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on 2020-07-20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contents](Contents.ipynb)\n",
    "• [Next: Time series graphics](02-Time-series-graphics.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
